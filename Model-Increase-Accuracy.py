# -*- coding: utf-8 -*-
"""Combining Multiple Classifier by_GhiasAli.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13Azau9luZTHGO6h0ARq9DuGvd1rSBF9l
"""

!pip install pyspark

from pyspark.ml.classification import DecisionTreeClassifier,NaiveBayes,LinearSVC,RandomForestClassifier
from pyspark.ml.feature import VectorAssembler,StringIndexer,StandardScaler
from pyspark.sql.functions import when,count,col

from pyspark.sql import SparkSession
spark=SparkSession.builder.getOrCreate()

df=spark.read.csv("cancerdata_test.csv",header=True,inferSchema=True)

df.show()

df.select("id","_c32").show()
#As these two columns do not give information, so we'll drop it

"""**Droping two columns having null values and give no infromation**"""

df=df.drop("id").drop("_c32")

df.groupBy("diagnosis").count().show()

"""**dataset target column contains None and NULL values, so i have replaced with most values in target column i-e "M"**"""

cols=[c for c in df.columns if c!='diagnosis']

df=df.withColumn("diagnosis",when(df.diagnosis=="None","M").when(df.diagnosis=="NULL","M").otherwise(df.diagnosis))

df.groupBy("diagnosis").count().show()

df.show()





va=VectorAssembler(inputCols=cols,outputCol='features')

vaDF=va.transform(df)

vaDF.show()

si=StringIndexer(inputCol='diagnosis',outputCol='indexedLabel')

siDF=si.fit(vaDF).transform(vaDF)

siDF.columns

ss=StandardScaler(inputCol='features',outputCol='scaledFeatures')

ssDF=ss.fit(siDF).transform(siDF)

ssDF=ssDF.select('scaledFeatures','indexedLabel')

ssDF.show()

finalDF=ssDF

finalDF.show()



"""**Here user will input for the number of bootstrap**"""



NumBootstrap = input ("Please enter the number of bootstrap :")

NumBootstrap=int(NumBootstrap)



BootstrapDataList=[]

"""**Creating Bootstrap (with replacement of data)**"""

for i in range(0,NumBootstrap):
  BootstrapDataList.append(finalDF.sample(withReplacement=True,fraction=1.0))

#Records in each bootsrap
for i in range(0,NumBootstrap):
  BootstrapDataList[i].groupBy('indexedLabel').count().show()

finalDF.first()

finalDF.show(truncate=False)

finalDF.count()

train,testoneRowDF=finalDF.randomSplit([0.7,0.3])

testoneRowDF.show(truncate=False)
testoneRowDF.printSchema()

BootstrapModelList=[]

dt=DecisionTreeClassifier(featuresCol='scaledFeatures',labelCol='indexedLabel')
rf=RandomForestClassifier(featuresCol='scaledFeatures',labelCol='indexedLabel')
nb = NaiveBayes(featuresCol='scaledFeatures',labelCol='indexedLabel')



"""**Creating three different models , i-e
1)DecesionTree
2)RandomForest
3)NaiveBsys**
"""

#Currently i only use three different classifier and apply on three 
#different bootstrap but we can increase the classifier
dtModel1=dt.fit(BootstrapDataList[0])
nbModel1=nb.fit(BootstrapDataList[1])
rfModel1=rf.fit(BootstrapDataList[2])

print("DeceisionTree Result")
dtModel1.transform(testoneRowDF).sort('scaledFeatures').show(5)
print("NaiveBays Result")
nbModel1.transform(testoneRowDF).sort('scaledFeatures').show(5)
print("RandomForest Result")
rfModel1.transform(testoneRowDF).sort('scaledFeatures').show(5)

predictedByDt=dtModel1.transform(testoneRowDF)
predictedByRf=rfModel1.transform(testoneRowDF)
predictedByNb=nbModel1.transform(testoneRowDF)

"""**Prediction of each model** """

print("DecisionTree prediction")
predictedByDt.show()
print("Randrom Forest prediction")

predictedByRf.show()
print("Naive Bays prediction")

predictedByNb.show()

testoneRowDF.show()

from pyspark.sql.functions import lit

predictedByDt1=predictedByDt.withColumn("pred_DT",predictedByDt.prediction)

predictedByDt1.show()

predictedByRf1=predictedByRf.withColumn("pred_RF",predictedByRf.prediction).select("pred_RF")

predictedByRf1.show()

predictedByRf1=predictedByRf1.join(predictedByDt1)
predictedByRf1.show()

predictedByRf1=predictedByRf1.select(predictedByRf1[0],predictedByRf1[1],predictedByRf1[2],predictedByRf1[6])

predictedByNb1=predictedByNb.withColumn("pred_NB",predictedByNb.prediction)

predictedByNb1=predictedByNb1.select("pred_NB")

predictedByNb1.show()

predictedByNb1=predictedByNb1.join(predictedByRf1)

predictedByNb1.show()

finalPredictedDF=predictedByNb1

finalPredictedDF.show()

import pyspark.sql.functions as F

"""**Below is the condition for voting i-e if 2 of 3 classifier
gives 1 result, then the votedLabel will be 1 otherwise 0 ** bold text
"""

#Below is the condition for voting i-e if 2 of 3 classifier
#gives 1 result, then the votedLabel will be 1 otherwise 0
finalVotedDF=finalPredictedDF.withColumn('votedLabel', F.when(((F.col("pred_NB") == 1) & (F.col("pred_RF") == 1)) | 
                                           ((F.col("pred_NB") == 1) & (F.col("pred_DT") == 1)) |
                                           ((F.col("pred_DT") == 1) & (F.col("pred_RF") == 1))
                                           , 1).otherwise(0))

# indexedLabel shows actualLabel
# pred_NB shows prediction by Naive Bays
# pred_DT shows prediction by DecisionTree
# pred_RF shows prediction by RandomForest


finalVotedDF.select("scaledFeatures","indexedLabel","pred_NB","pred_DT","pred_RF","votedLabel").show(150)

from pyspark.ml.evaluation import MulticlassClassificationEvaluator

from pyspark.sql.types import DoubleType
finalVotedDF = finalVotedDF.withColumn("votedLabel", finalVotedDF.votedLabel.cast(DoubleType()))

votedevaluator = MulticlassClassificationEvaluator(
    labelCol="indexedLabel", predictionCol="votedLabel", metricName="accuracy")
votedaccuracy = votedevaluator.evaluate(finalVotedDF)
print("voted Accuracy: ",accuracy)

NBevaluator = MulticlassClassificationEvaluator(
    labelCol="indexedLabel", predictionCol="pred_NB", metricName="accuracy")
NBaccuracy = NBevaluator.evaluate(finalVotedDF)
print("Naive Bays Accuracy: ",NBaccuracy)

# so voted label accuracy is better than Naive bays accuracy

